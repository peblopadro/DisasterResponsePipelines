{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///DataBase.db')\n",
    "df = pd.read_sql('SELECT * FROM df', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>Cyclone nan fini osinon li pa fini</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Looking for someone but no name</td>\n",
       "      <td>Patnm, di Maryani relem pou li banm nouvel li ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...   \n",
       "1   7            Is the Hurricane over or is it not over   \n",
       "2   8                    Looking for someone but no name   \n",
       "\n",
       "                                            original   genre  related  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct        1   \n",
       "1                 Cyclone nan fini osinon li pa fini  direct        1   \n",
       "2  Patnm, di Maryani relem pou li banm nouvel li ...  direct        1   \n",
       "\n",
       "   request  offer  aid_related  medical_help  medical_products      ...        \\\n",
       "0        0      0            0             0                 0      ...         \n",
       "1        0      0            1             0                 0      ...         \n",
       "2        0      0            0             0                 0      ...         \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0            0                     0                0       0      0     0   \n",
       "1            0                     0                1       0      1     0   \n",
       "2            0                     0                0       0      0     0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0           0     0              0              0  \n",
       "1           0     0              0              0  \n",
       "2           0     0              0              0  \n",
       "\n",
       "[3 rows x 40 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['direct', 'social', 'news'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.genre.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cleaning non-binary columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    19906\n",
       "0     6122\n",
       "2      188\n",
       "Name: related, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.related.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_samples = []\n",
    "for i in df.index:\n",
    "    if df.loc[i,'related'] == 2:\n",
    "        bad_samples.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bad_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_samples = [i for i in df.index if i not in bad_samples ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26216, 26216)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking:\n",
    "len(good_samples)+len(bad_samples), df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>Cyclone nan fini osinon li pa fini</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...   \n",
       "1   7            Is the Hurricane over or is it not over   \n",
       "\n",
       "                                            original   genre  related  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct        1   \n",
       "1                 Cyclone nan fini osinon li pa fini  direct        1   \n",
       "\n",
       "   request  offer  aid_related  medical_help  medical_products      ...        \\\n",
       "0        0      0            0             0                 0      ...         \n",
       "1        0      0            1             0                 0      ...         \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0            0                     0                0       0      0     0   \n",
       "1            0                     0                1       0      1     0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0           0     0              0              0  \n",
       "1           0     0              0              0  \n",
       "\n",
       "[2 rows x 40 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[good_samples,]\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    19906\n",
       "0     6122\n",
       "Name: related, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final check:\n",
    "df.related.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### splitting  feature vs target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Weather update - a cold front from Cuba that c...\n",
       "1              Is the Hurricane over or is it not over\n",
       "2                      Looking for someone but no name\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[features]\n",
    "X = X['message']\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'message', 'original', 'genre']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_target_cols = ['id','message','original','genre'] \n",
    "non_target_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['related', 'request', 'offer', 'aid_related', 'medical_help',\n",
       "       'medical_products', 'search_and_rescue', 'security', 'military',\n",
       "       'child_alone', 'water', 'food', 'shelter', 'clothing', 'money',\n",
       "       'missing_people', 'refugees', 'death', 'other_aid',\n",
       "       'infrastructure_related', 'transport', 'buildings', 'electricity',\n",
       "       'tools', 'hospitals', 'shops', 'aid_centers', 'other_infrastructure',\n",
       "       'weather_related', 'floods', 'storm', 'fire', 'earthquake', 'cold',\n",
       "       'other_weather', 'direct_report'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_cols = df.columns[~df.columns.isin(non_target_cols)]\n",
    "target_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>child_alone</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   related  request  offer  aid_related  medical_help  medical_products  \\\n",
       "0        1        0      0            0             0                 0   \n",
       "1        1        0      0            1             0                 0   \n",
       "2        1        0      0            0             0                 0   \n",
       "\n",
       "   search_and_rescue  security  military  child_alone      ...        \\\n",
       "0                  0         0         0            0      ...         \n",
       "1                  0         0         0            0      ...         \n",
       "2                  0         0         0            0      ...         \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0            0                     0                0       0      0     0   \n",
       "1            0                     0                1       0      1     0   \n",
       "2            0                     0                0       0      0     0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0           0     0              0              0  \n",
       "1           0     0              0              0  \n",
       "2           0     0              0              0  \n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = df[target_cols]\n",
    "Y.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize) ),\n",
    "    ('tfidf', TfidfTransformer() ),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier() ) )\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "word_tokenize(X_train.iloc[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tokenize(X_train.iloc[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cv = CountVectorizer(tokenizer=tokenize)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cv.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19521,), (19521, 36))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape , Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6507, 36), (6507, 36))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Y_test.shape, Y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[pandas.core.frame.DataFrame, numpy.ndarray]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[type(Y_test), type(Y_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>child_alone</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   related  request  offer  aid_related  medical_help  medical_products  \\\n",
       "0        1        0      0            0             0                 0   \n",
       "1        1        0      0            0             0                 0   \n",
       "\n",
       "   search_and_rescue  security  military  child_alone      ...        \\\n",
       "0                  0         0         0            0      ...         \n",
       "1                  0         0         0            0      ...         \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0            0                     0                1       1      1     0   \n",
       "1            0                     0                1       0      0     0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0           0     0              0              0  \n",
       "1           1     0              0              0  \n",
       "\n",
       "[2 rows x 36 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = pd.DataFrame(Y_pred,columns=Y_test.columns)\n",
    "Y_pred.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.multiclass import type_of_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['multilabel-indicator', 'multilabel-indicator']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[type_of_target(Y_test), type_of_target(Y_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Signature (y_true, y_pred, labels=None, target_names=None, sample_weight=None, digits=2)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "inspect.signature(classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.84      0.92      0.88      4981\n",
      "               request       0.77      0.41      0.53      1114\n",
      "                 offer       0.00      0.00      0.00        31\n",
      "           aid_related       0.73      0.61      0.66      2655\n",
      "          medical_help       0.50      0.08      0.14       522\n",
      "      medical_products       0.66      0.08      0.14       342\n",
      "     search_and_rescue       0.40      0.04      0.07       164\n",
      "              security       0.50      0.01      0.01       132\n",
      "              military       0.60      0.12      0.20       208\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.85      0.44      0.58       440\n",
      "                  food       0.83      0.55      0.66       693\n",
      "               shelter       0.81      0.41      0.54       606\n",
      "              clothing       1.00      0.05      0.09       107\n",
      "                 money       0.75      0.02      0.04       143\n",
      "        missing_people       1.00      0.02      0.04        89\n",
      "              refugees       0.61      0.05      0.09       237\n",
      "                 death       0.69      0.19      0.30       301\n",
      "             other_aid       0.54      0.06      0.12       837\n",
      "infrastructure_related       0.11      0.00      0.01       413\n",
      "             transport       0.72      0.13      0.22       308\n",
      "             buildings       0.52      0.11      0.18       320\n",
      "           electricity       0.80      0.06      0.11       135\n",
      "                 tools       0.00      0.00      0.00        42\n",
      "             hospitals       0.50      0.01      0.03        75\n",
      "                 shops       0.00      0.00      0.00        30\n",
      "           aid_centers       0.00      0.00      0.00        74\n",
      "  other_infrastructure       0.08      0.00      0.01       274\n",
      "       weather_related       0.84      0.59      0.69      1887\n",
      "                floods       0.85      0.37      0.52       553\n",
      "                 storm       0.75      0.38      0.50       617\n",
      "                  fire       1.00      0.03      0.05        78\n",
      "            earthquake       0.88      0.73      0.80       641\n",
      "                  cold       0.67      0.08      0.14       150\n",
      "         other_weather       0.64      0.04      0.08       364\n",
      "         direct_report       0.72      0.31      0.43      1265\n",
      "\n",
      "           avg / total       0.73      0.49      0.55     20828\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,Y_pred,target_names=Y_test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.246561690716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(f1_score((Y_test), (Y_pred),average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters in CountVectorizer\n",
    "inspect.signature(CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters in TfidfTransformer\n",
    "inspect.signature(TfidfTransformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters in RandomForestClassifier\n",
    "inspect.signature(RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for param in cv.get_params().keys():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['memory',\n",
       " 'steps',\n",
       " 'vect',\n",
       " 'tfidf',\n",
       " 'clf',\n",
       " 'vect__analyzer',\n",
       " 'vect__binary',\n",
       " 'vect__decode_error',\n",
       " 'vect__dtype',\n",
       " 'vect__encoding',\n",
       " 'vect__input',\n",
       " 'vect__lowercase',\n",
       " 'vect__max_df',\n",
       " 'vect__max_features',\n",
       " 'vect__min_df',\n",
       " 'vect__ngram_range',\n",
       " 'vect__preprocessor',\n",
       " 'vect__stop_words',\n",
       " 'vect__strip_accents',\n",
       " 'vect__token_pattern',\n",
       " 'vect__tokenizer',\n",
       " 'vect__vocabulary',\n",
       " 'tfidf__norm',\n",
       " 'tfidf__smooth_idf',\n",
       " 'tfidf__sublinear_tf',\n",
       " 'tfidf__use_idf',\n",
       " 'clf__estimator__bootstrap',\n",
       " 'clf__estimator__class_weight',\n",
       " 'clf__estimator__criterion',\n",
       " 'clf__estimator__max_depth',\n",
       " 'clf__estimator__max_features',\n",
       " 'clf__estimator__max_leaf_nodes',\n",
       " 'clf__estimator__min_impurity_decrease',\n",
       " 'clf__estimator__min_impurity_split',\n",
       " 'clf__estimator__min_samples_leaf',\n",
       " 'clf__estimator__min_samples_split',\n",
       " 'clf__estimator__min_weight_fraction_leaf',\n",
       " 'clf__estimator__n_estimators',\n",
       " 'clf__estimator__n_jobs',\n",
       " 'clf__estimator__oob_score',\n",
       " 'clf__estimator__random_state',\n",
       " 'clf__estimator__verbose',\n",
       " 'clf__estimator__warm_start',\n",
       " 'clf__estimator',\n",
       " 'clf__n_jobs']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pipeline.get_params().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vect__tokenizer': [tokenize,None], # for count vectorizer\n",
    "    'tfidf__norm': ['l1','l2'], # for tfidf\n",
    "    'clf__estimator__criterion': ['gini','entropy'] # for Random Forest\n",
    "}\n",
    "\n",
    "# Note: using 'clf__criterion' as syntax generates an error:\n",
    "# ValueError: Invalid parameter criterion for estimator MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "# By doing cv.get_params().keys() one can see the above one is the right syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect.signature(GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = GridSearchCV(pipeline, param_grid=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'vect__tokenizer': [<function tokenize at 0x7f583a126a60>, None], 'tfidf__norm': ['l1', 'l2'], 'clf__estimator__criterion': ['gini', 'entropy']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__estimator__criterion</th>\n",
       "      <th>param_tfidf__norm</th>\n",
       "      <th>param_vect__tokenizer</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.574330</td>\n",
       "      <td>0.252547</td>\n",
       "      <td>4.464049</td>\n",
       "      <td>0.098948</td>\n",
       "      <td>gini</td>\n",
       "      <td>l1</td>\n",
       "      <td>&lt;function tokenize at 0x7f583a126a60&gt;</td>\n",
       "      <td>{'clf__estimator__criterion': 'gini', 'tfidf__...</td>\n",
       "      <td>0.233134</td>\n",
       "      <td>0.233134</td>\n",
       "      <td>0.244506</td>\n",
       "      <td>0.236924</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>4</td>\n",
       "      <td>0.803827</td>\n",
       "      <td>0.803750</td>\n",
       "      <td>0.807208</td>\n",
       "      <td>0.804928</td>\n",
       "      <td>0.001612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.335796</td>\n",
       "      <td>0.535433</td>\n",
       "      <td>1.681924</td>\n",
       "      <td>0.013685</td>\n",
       "      <td>gini</td>\n",
       "      <td>l1</td>\n",
       "      <td>None</td>\n",
       "      <td>{'clf__estimator__criterion': 'gini', 'tfidf__...</td>\n",
       "      <td>0.213923</td>\n",
       "      <td>0.221454</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.219200</td>\n",
       "      <td>0.003744</td>\n",
       "      <td>7</td>\n",
       "      <td>0.810973</td>\n",
       "      <td>0.807054</td>\n",
       "      <td>0.811050</td>\n",
       "      <td>0.809692</td>\n",
       "      <td>0.001866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.549490</td>\n",
       "      <td>0.469520</td>\n",
       "      <td>4.416410</td>\n",
       "      <td>0.035773</td>\n",
       "      <td>gini</td>\n",
       "      <td>l2</td>\n",
       "      <td>&lt;function tokenize at 0x7f583a126a60&gt;</td>\n",
       "      <td>{'clf__estimator__criterion': 'gini', 'tfidf__...</td>\n",
       "      <td>0.237437</td>\n",
       "      <td>0.232365</td>\n",
       "      <td>0.246350</td>\n",
       "      <td>0.238717</td>\n",
       "      <td>0.005781</td>\n",
       "      <td>2</td>\n",
       "      <td>0.811280</td>\n",
       "      <td>0.810589</td>\n",
       "      <td>0.804749</td>\n",
       "      <td>0.808872</td>\n",
       "      <td>0.002930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.201870</td>\n",
       "      <td>0.238465</td>\n",
       "      <td>1.698327</td>\n",
       "      <td>0.020997</td>\n",
       "      <td>gini</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>{'clf__estimator__criterion': 'gini', 'tfidf__...</td>\n",
       "      <td>0.218227</td>\n",
       "      <td>0.217458</td>\n",
       "      <td>0.230521</td>\n",
       "      <td>0.222069</td>\n",
       "      <td>0.005985</td>\n",
       "      <td>6</td>\n",
       "      <td>0.808591</td>\n",
       "      <td>0.808053</td>\n",
       "      <td>0.809743</td>\n",
       "      <td>0.808796</td>\n",
       "      <td>0.000705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.529523</td>\n",
       "      <td>0.443410</td>\n",
       "      <td>4.085497</td>\n",
       "      <td>0.054451</td>\n",
       "      <td>entropy</td>\n",
       "      <td>l1</td>\n",
       "      <td>&lt;function tokenize at 0x7f583a126a60&gt;</td>\n",
       "      <td>{'clf__estimator__criterion': 'entropy', 'tfid...</td>\n",
       "      <td>0.239281</td>\n",
       "      <td>0.232519</td>\n",
       "      <td>0.245274</td>\n",
       "      <td>0.239025</td>\n",
       "      <td>0.005211</td>\n",
       "      <td>1</td>\n",
       "      <td>0.807361</td>\n",
       "      <td>0.806670</td>\n",
       "      <td>0.807669</td>\n",
       "      <td>0.807233</td>\n",
       "      <td>0.000418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33.222514</td>\n",
       "      <td>0.280653</td>\n",
       "      <td>1.297310</td>\n",
       "      <td>0.011502</td>\n",
       "      <td>entropy</td>\n",
       "      <td>l1</td>\n",
       "      <td>None</td>\n",
       "      <td>{'clf__estimator__criterion': 'entropy', 'tfid...</td>\n",
       "      <td>0.224681</td>\n",
       "      <td>0.214999</td>\n",
       "      <td>0.228062</td>\n",
       "      <td>0.222581</td>\n",
       "      <td>0.005536</td>\n",
       "      <td>5</td>\n",
       "      <td>0.802905</td>\n",
       "      <td>0.799831</td>\n",
       "      <td>0.802136</td>\n",
       "      <td>0.801624</td>\n",
       "      <td>0.001306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40.911137</td>\n",
       "      <td>0.571830</td>\n",
       "      <td>4.072481</td>\n",
       "      <td>0.045474</td>\n",
       "      <td>entropy</td>\n",
       "      <td>l2</td>\n",
       "      <td>&lt;function tokenize at 0x7f583a126a60&gt;</td>\n",
       "      <td>{'clf__estimator__criterion': 'entropy', 'tfid...</td>\n",
       "      <td>0.239742</td>\n",
       "      <td>0.235900</td>\n",
       "      <td>0.240510</td>\n",
       "      <td>0.238717</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>2</td>\n",
       "      <td>0.812202</td>\n",
       "      <td>0.808207</td>\n",
       "      <td>0.805363</td>\n",
       "      <td>0.808591</td>\n",
       "      <td>0.002805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>33.120191</td>\n",
       "      <td>0.218528</td>\n",
       "      <td>1.299065</td>\n",
       "      <td>0.002380</td>\n",
       "      <td>entropy</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>{'clf__estimator__criterion': 'entropy', 'tfid...</td>\n",
       "      <td>0.212079</td>\n",
       "      <td>0.214538</td>\n",
       "      <td>0.221300</td>\n",
       "      <td>0.215973</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>8</td>\n",
       "      <td>0.802213</td>\n",
       "      <td>0.808744</td>\n",
       "      <td>0.801982</td>\n",
       "      <td>0.804313</td>\n",
       "      <td>0.003135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      39.574330      0.252547         4.464049        0.098948   \n",
       "1      32.335796      0.535433         1.681924        0.013685   \n",
       "2      38.549490      0.469520         4.416410        0.035773   \n",
       "3      32.201870      0.238465         1.698327        0.020997   \n",
       "4      40.529523      0.443410         4.085497        0.054451   \n",
       "5      33.222514      0.280653         1.297310        0.011502   \n",
       "6      40.911137      0.571830         4.072481        0.045474   \n",
       "7      33.120191      0.218528         1.299065        0.002380   \n",
       "\n",
       "  param_clf__estimator__criterion param_tfidf__norm  \\\n",
       "0                            gini                l1   \n",
       "1                            gini                l1   \n",
       "2                            gini                l2   \n",
       "3                            gini                l2   \n",
       "4                         entropy                l1   \n",
       "5                         entropy                l1   \n",
       "6                         entropy                l2   \n",
       "7                         entropy                l2   \n",
       "\n",
       "                   param_vect__tokenizer  \\\n",
       "0  <function tokenize at 0x7f583a126a60>   \n",
       "1                                   None   \n",
       "2  <function tokenize at 0x7f583a126a60>   \n",
       "3                                   None   \n",
       "4  <function tokenize at 0x7f583a126a60>   \n",
       "5                                   None   \n",
       "6  <function tokenize at 0x7f583a126a60>   \n",
       "7                                   None   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'clf__estimator__criterion': 'gini', 'tfidf__...           0.233134   \n",
       "1  {'clf__estimator__criterion': 'gini', 'tfidf__...           0.213923   \n",
       "2  {'clf__estimator__criterion': 'gini', 'tfidf__...           0.237437   \n",
       "3  {'clf__estimator__criterion': 'gini', 'tfidf__...           0.218227   \n",
       "4  {'clf__estimator__criterion': 'entropy', 'tfid...           0.239281   \n",
       "5  {'clf__estimator__criterion': 'entropy', 'tfid...           0.224681   \n",
       "6  {'clf__estimator__criterion': 'entropy', 'tfid...           0.239742   \n",
       "7  {'clf__estimator__criterion': 'entropy', 'tfid...           0.212079   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.233134           0.244506         0.236924        0.005361   \n",
       "1           0.221454           0.222222         0.219200        0.003744   \n",
       "2           0.232365           0.246350         0.238717        0.005781   \n",
       "3           0.217458           0.230521         0.222069        0.005985   \n",
       "4           0.232519           0.245274         0.239025        0.005211   \n",
       "5           0.214999           0.228062         0.222581        0.005536   \n",
       "6           0.235900           0.240510         0.238717        0.002017   \n",
       "7           0.214538           0.221300         0.215973        0.003899   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                4            0.803827            0.803750   \n",
       "1                7            0.810973            0.807054   \n",
       "2                2            0.811280            0.810589   \n",
       "3                6            0.808591            0.808053   \n",
       "4                1            0.807361            0.806670   \n",
       "5                5            0.802905            0.799831   \n",
       "6                2            0.812202            0.808207   \n",
       "7                8            0.802213            0.808744   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0            0.807208          0.804928         0.001612  \n",
       "1            0.811050          0.809692         0.001866  \n",
       "2            0.804749          0.808872         0.002930  \n",
       "3            0.809743          0.808796         0.000705  \n",
       "4            0.807669          0.807233         0.000418  \n",
       "5            0.802136          0.801624         0.001306  \n",
       "6            0.805363          0.808591         0.002805  \n",
       "7            0.801982          0.804313         0.003135  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23902464013114083"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__estimator__criterion': 'entropy',\n",
       " 'tfidf__norm': 'l1',\n",
       " 'vect__tokenizer': <function __main__.tokenize(text)>}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cv.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_cv = cv.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.85      0.92      0.89      4981\n",
      "               request       0.82      0.42      0.55      1114\n",
      "                 offer       0.00      0.00      0.00        31\n",
      "           aid_related       0.74      0.61      0.67      2655\n",
      "          medical_help       0.58      0.08      0.14       522\n",
      "      medical_products       0.64      0.03      0.05       342\n",
      "     search_and_rescue       1.00      0.06      0.11       164\n",
      "              security       0.50      0.01      0.01       132\n",
      "              military       0.54      0.03      0.06       208\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.88      0.29      0.44       440\n",
      "                  food       0.78      0.52      0.62       693\n",
      "               shelter       0.79      0.26      0.39       606\n",
      "              clothing       0.86      0.06      0.11       107\n",
      "                 money       0.80      0.03      0.05       143\n",
      "        missing_people       0.00      0.00      0.00        89\n",
      "              refugees       0.67      0.04      0.08       237\n",
      "                 death       0.84      0.09      0.16       301\n",
      "             other_aid       0.52      0.04      0.07       837\n",
      "infrastructure_related       0.00      0.00      0.00       413\n",
      "             transport       0.78      0.08      0.15       308\n",
      "             buildings       0.67      0.10      0.17       320\n",
      "           electricity       1.00      0.01      0.03       135\n",
      "                 tools       0.00      0.00      0.00        42\n",
      "             hospitals       0.00      0.00      0.00        75\n",
      "                 shops       0.00      0.00      0.00        30\n",
      "           aid_centers       0.00      0.00      0.00        74\n",
      "  other_infrastructure       0.17      0.00      0.01       274\n",
      "       weather_related       0.84      0.60      0.70      1887\n",
      "                floods       0.82      0.21      0.34       553\n",
      "                 storm       0.78      0.28      0.42       617\n",
      "                  fire       0.00      0.00      0.00        78\n",
      "            earthquake       0.88      0.63      0.73       641\n",
      "                  cold       0.91      0.07      0.12       150\n",
      "         other_weather       0.67      0.01      0.02       364\n",
      "         direct_report       0.75      0.32      0.45      1265\n",
      "\n",
      "           avg / total       0.74      0.47      0.52     20828\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,Y_pred_cv,target_names=Y_test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.246561690716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(Y_test,Y_pred,average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "list(GradientBoostingClassifier().get_params().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### verb extractor method from class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "nltk.download(['punkt', 'wordnet', 'averaged_perceptron_tagger'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StartingVerbExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def starting_verb(self, text):\n",
    "        sentence_list = nltk.sent_tokenize(text)\n",
    "        for sentence in sentence_list:\n",
    "            pos_tags = nltk.pos_tag(tokenize(sentence))\n",
    "            first_word, first_tag = pos_tags[0]\n",
    "            if first_tag in ['VB', 'VBP'] or first_word == 'RT':\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_tagged = pd.Series(X).apply(self.starting_verb)\n",
    "        return pd.DataFrame(X_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## from Mentor:\n",
    "\n",
    "class StartingVerbExtractor(BaseEstimator, TransformerMixin):\n",
    "    def starting_verb(self, text):\n",
    "        sentence_list = nltk.sent_tokenize(text)\n",
    "        for sentence in sentence_list:\n",
    "            pos_tags = nltk.pos_tag(tokenize(sentence))\n",
    "            try:\n",
    "                first_word, first_tag = pos_tags[0]\n",
    "                if first_tag in ['VB', 'VBP'] or first_word == 'RT':\n",
    "                    return True\n",
    "            except:\n",
    "                return False\n",
    "        return False\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_tagged = pd.Series(X).apply(self.starting_verb)\n",
    "        return pd.DataFrame(X_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_improved = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('nlp_pipeline',  Pipeline([\n",
    "            ('vect', CountVectorizer(tokenizer=tokenize) ),\n",
    "            ('tfidf', TfidfTransformer() )\n",
    "                                  ]) ),\n",
    "        ('txt_extract', StartingVerbExtractor() )\n",
    "                            ]) ),      \n",
    "        \n",
    "    ('knn', MultiOutputClassifier(KNeighborsClassifier() ) )\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['memory',\n",
       " 'steps',\n",
       " 'features',\n",
       " 'knn',\n",
       " 'features__n_jobs',\n",
       " 'features__transformer_list',\n",
       " 'features__transformer_weights',\n",
       " 'features__nlp_pipeline',\n",
       " 'features__txt_extract',\n",
       " 'features__nlp_pipeline__memory',\n",
       " 'features__nlp_pipeline__steps',\n",
       " 'features__nlp_pipeline__vect',\n",
       " 'features__nlp_pipeline__tfidf',\n",
       " 'features__nlp_pipeline__vect__analyzer',\n",
       " 'features__nlp_pipeline__vect__binary',\n",
       " 'features__nlp_pipeline__vect__decode_error',\n",
       " 'features__nlp_pipeline__vect__dtype',\n",
       " 'features__nlp_pipeline__vect__encoding',\n",
       " 'features__nlp_pipeline__vect__input',\n",
       " 'features__nlp_pipeline__vect__lowercase',\n",
       " 'features__nlp_pipeline__vect__max_df',\n",
       " 'features__nlp_pipeline__vect__max_features',\n",
       " 'features__nlp_pipeline__vect__min_df',\n",
       " 'features__nlp_pipeline__vect__ngram_range',\n",
       " 'features__nlp_pipeline__vect__preprocessor',\n",
       " 'features__nlp_pipeline__vect__stop_words',\n",
       " 'features__nlp_pipeline__vect__strip_accents',\n",
       " 'features__nlp_pipeline__vect__token_pattern',\n",
       " 'features__nlp_pipeline__vect__tokenizer',\n",
       " 'features__nlp_pipeline__vect__vocabulary',\n",
       " 'features__nlp_pipeline__tfidf__norm',\n",
       " 'features__nlp_pipeline__tfidf__smooth_idf',\n",
       " 'features__nlp_pipeline__tfidf__sublinear_tf',\n",
       " 'features__nlp_pipeline__tfidf__use_idf',\n",
       " 'knn__estimator__algorithm',\n",
       " 'knn__estimator__leaf_size',\n",
       " 'knn__estimator__metric',\n",
       " 'knn__estimator__metric_params',\n",
       " 'knn__estimator__n_jobs',\n",
       " 'knn__estimator__n_neighbors',\n",
       " 'knn__estimator__p',\n",
       " 'knn__estimator__weights',\n",
       " 'knn__estimator',\n",
       " 'knn__n_jobs']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pipeline_improved.get_params().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = pipeline_improved.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function sklearn.pipeline.Pipeline.score(self, X, y=None, sample_weight=None)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes_\n",
      "decision_function\n",
      "fit\n",
      "fit_predict\n",
      "fit_transform\n",
      "get_params\n",
      "inverse_transform\n",
      "memory\n",
      "named_steps\n",
      "predict\n",
      "predict_log_proba\n",
      "predict_proba\n",
      "score\n",
      "set_params\n",
      "steps\n",
      "transform\n"
     ]
    }
   ],
   "source": [
    "for att in dir(knn):\n",
    "    if not att.startswith('_'):\n",
    "        print(att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_improved = pipeline_improved.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.82      0.93      0.87      4981\n",
      "               request       0.68      0.43      0.52      1114\n",
      "                 offer       0.00      0.00      0.00        31\n",
      "           aid_related       0.68      0.43      0.53      2655\n",
      "          medical_help       0.63      0.10      0.17       522\n",
      "      medical_products       0.61      0.11      0.19       342\n",
      "     search_and_rescue       0.56      0.05      0.10       164\n",
      "              security       0.00      0.00      0.00       132\n",
      "              military       0.72      0.10      0.18       208\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.71      0.22      0.33       440\n",
      "                  food       0.67      0.31      0.43       693\n",
      "               shelter       0.64      0.15      0.24       606\n",
      "              clothing       0.67      0.11      0.19       107\n",
      "                 money       0.61      0.08      0.14       143\n",
      "        missing_people       0.00      0.00      0.00        89\n",
      "              refugees       0.31      0.02      0.03       237\n",
      "                 death       0.74      0.16      0.26       301\n",
      "             other_aid       0.38      0.07      0.11       837\n",
      "infrastructure_related       0.32      0.02      0.04       413\n",
      "             transport       0.61      0.06      0.11       308\n",
      "             buildings       0.59      0.09      0.16       320\n",
      "           electricity       0.79      0.08      0.15       135\n",
      "                 tools       0.00      0.00      0.00        42\n",
      "             hospitals       0.50      0.01      0.03        75\n",
      "                 shops       0.00      0.00      0.00        30\n",
      "           aid_centers       0.00      0.00      0.00        74\n",
      "  other_infrastructure       0.12      0.01      0.01       274\n",
      "       weather_related       0.74      0.38      0.50      1887\n",
      "                floods       0.76      0.15      0.25       553\n",
      "                 storm       0.67      0.21      0.31       617\n",
      "                  fire       0.83      0.06      0.12        78\n",
      "            earthquake       0.77      0.44      0.56       641\n",
      "                  cold       0.50      0.05      0.09       150\n",
      "         other_weather       0.49      0.05      0.10       364\n",
      "         direct_report       0.64      0.31      0.42      1265\n",
      "\n",
      "           avg / total       0.67      0.41      0.47     20828\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,Y_pred_improved,target_names=Y_test.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.19827520437555368"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = f1_score(Y_test,Y_pred_improved, average='macro')\n",
    "score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "type(report)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline with two estimators:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "estimators = [('knn', MultiOutputClassifier(KNeighborsClassifier()  )),\n",
    "              ('clf', MultiOutputClassifier(RandomForestClassifier()))]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('nlp_pipeline',  Pipeline([\n",
    "            ('vect', CountVectorizer(tokenizer=tokenize) ),\n",
    "            ('tfidf', TfidfTransformer() )]) ),\n",
    "        ('txt_extract', StartingVerbExtractor() )]) ),      \n",
    "    ('estimators', [('knn', MultiOutputClassifier(KNeighborsClassifier()  )),\n",
    "                    ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "                   ]\n",
    "     )\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(knn,open('knn.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(cv.best_estimator_,open('rfc_cv.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf,open('clf.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump( , \"classifier.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing `train_classifier.py` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download(['punkt', 'wordnet', 'averaged_perceptron_tagger'])\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pickle\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_filepath, model_filepath = sys.argv[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/.local/share/jupyter/runtime/kernel-ec344199-f04e-4ab8-b530-50f52ddffac0.json'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-f'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(database_filepath):\n",
    "    \"\"\"\n",
    "    Loads data from SQL Database and transforms it for model training\n",
    "    \n",
    "    :param database_filepath: SQL database file (string)\n",
    "    \n",
    "    :returns x: Features (dataframe)\n",
    "    :returns y: Targets (dataframe)\n",
    "    :returns category_names: Target labels (list)\n",
    "    \"\"\"\n",
    "    \n",
    "    engine = create_engine('sqlite:///{}'.format(database_filepath))\n",
    "    df = pd.read_sql('SELECT * FROM df', engine)\n",
    "    \n",
    "    bad_samples = []\n",
    "    for i in df.index:\n",
    "        if df.loc[i,'related'] == 2:\n",
    "            bad_samples.append(i)\n",
    "    good_samples = [i for i in df.index if i not in bad_samples ]   \n",
    "    df = df.iloc[good_samples,]   \n",
    "\n",
    "    features = ['message']\n",
    "    X = df[features]\n",
    "    X = X['message']\n",
    "    \n",
    "    non_target_cols = ['id','message','original','genre'] \n",
    "    target_cols = df.columns[~df.columns.isin(non_target_cols)]\n",
    "    Y = df[target_cols]\n",
    "    \n",
    "    category_names = Y.columns\n",
    "    return X,Y, category_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, category_names = load_data('DataBase.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Weather update - a cold front from Cuba that c...\n",
       "1              Is the Hurricane over or is it not over\n",
       "2                      Looking for someone but no name\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>child_alone</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   related  request  offer  aid_related  medical_help  medical_products  \\\n",
       "0        1        0      0            0             0                 0   \n",
       "1        1        0      0            1             0                 0   \n",
       "2        1        0      0            0             0                 0   \n",
       "\n",
       "   search_and_rescue  security  military  child_alone      ...        \\\n",
       "0                  0         0         0            0      ...         \n",
       "1                  0         0         0            0      ...         \n",
       "2                  0         0         0            0      ...         \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0            0                     0                0       0      0     0   \n",
       "1            0                     0                1       0      1     0   \n",
       "2            0                     0                0       0      0     0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0           0     0              0              0  \n",
       "1           0     0              0              0  \n",
       "2           0     0              0              0  \n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['related', 'request', 'offer', 'aid_related', 'medical_help',\n",
       "       'medical_products', 'search_and_rescue', 'security', 'military',\n",
       "       'child_alone', 'water', 'food', 'shelter', 'clothing', 'money',\n",
       "       'missing_people', 'refugees', 'death', 'other_aid',\n",
       "       'infrastructure_related', 'transport', 'buildings', 'electricity',\n",
       "       'tools', 'hospitals', 'shops', 'aid_centers', 'other_infrastructure',\n",
       "       'weather_related', 'floods', 'storm', 'fire', 'earthquake', 'cold',\n",
       "       'other_weather', 'direct_report'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### buil_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5206,), (5206, 36))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StartingVerbExtractor(BaseEstimator, TransformerMixin):\n",
    "    def starting_verb(self, text):\n",
    "        sentence_list = nltk.sent_tokenize(text)\n",
    "        for sentence in sentence_list:\n",
    "            pos_tags = nltk.pos_tag(tokenize(sentence))\n",
    "            try:\n",
    "                first_word, first_tag = pos_tags[0]\n",
    "                if first_tag in ['VB', 'VBP'] or first_word == 'RT':\n",
    "                    return True\n",
    "            except:\n",
    "                return False\n",
    "        return False\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_tagged = pd.Series(X).apply(self.starting_verb)\n",
    "        return pd.DataFrame(X_tagged) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \"\"\"\n",
    "    Builds a model using Random Forest Classifier. Data is transformed in pipeline using Tokenization, Count Vectorizer,\n",
    "    Tfidf Transformer and\n",
    "    \n",
    "    :return cv: Trained model after performing grid search (GridSearchCV model)\n",
    "    \"\"\"\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('nlp_pipeline',  Pipeline([\n",
    "            ('vect', CountVectorizer(tokenizer=tokenize) ),\n",
    "            ('tfidf', TfidfTransformer() )]) ),\n",
    "        ('txt_extract', StartingVerbExtractor() )]) ),          \n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier() ) )])\n",
    "    \n",
    "    parameters = {\n",
    "    'features__nlp_pipeline__vect__tokenizer': [tokenize,None], # for count vectorizer\n",
    "    'features__nlp_pipeline__tfidf__norm': ['l1','l2'], # for tfidf\n",
    "    'clf__estimator__criterion': ['gini','entropy']} # for Random Forest\n",
    "    \n",
    "    #cv = GridSearchCV(estimator=pipeline, param_grid=parameters,scoring='f1_macro')\n",
    "    \n",
    "    cv = pipeline\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('nlp_pipeline', Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate_model():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20822,), (20822, 36))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('nlp_pipeline', Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, Y_test, category_names):                     \n",
    "    \"\"\"\n",
    "    Measures model's performance on test data and prints out results.\n",
    "    :param model: trained model (GridSearchCV Object)\n",
    "    :param X_test: Test features (dataframe)\n",
    "    :param Y_test: Test targets (dataframe)\n",
    "    :param category_names: Target labels (dataframe)\n",
    "    \n",
    "    :return model_report: Dataframe with Model Performance report\n",
    "    \"\"\"             \n",
    "    Y_pred = model.predict(X_test) #best_estimator_\n",
    "    Y_pred = pd.DataFrame(Y_pred,columns=Y_test.columns)\n",
    "    #print(\"\\nBest Parameters:\", model.best_params_)\n",
    "    #score = f1_score( Y_test,Y_pred, average='macro')\n",
    "    \n",
    "    return print(classification_report(Y_test,Y_pred,target_names=category_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.84      0.92      0.88      3974\n",
      "               request       0.80      0.45      0.57       887\n",
      "                 offer       0.00      0.00      0.00        21\n",
      "           aid_related       0.75      0.60      0.67      2162\n",
      "          medical_help       0.55      0.09      0.15       410\n",
      "      medical_products       0.66      0.09      0.15       265\n",
      "     search_and_rescue       0.33      0.01      0.01       137\n",
      "              security       0.00      0.00      0.00        86\n",
      "              military       0.71      0.09      0.16       187\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.82      0.27      0.41       345\n",
      "                  food       0.86      0.54      0.66       578\n",
      "               shelter       0.78      0.28      0.41       446\n",
      "              clothing       0.60      0.08      0.14        78\n",
      "                 money       0.86      0.05      0.09       127\n",
      "        missing_people       1.00      0.04      0.07        57\n",
      "              refugees       0.50      0.04      0.08       157\n",
      "                 death       0.83      0.10      0.19       230\n",
      "             other_aid       0.51      0.06      0.11       676\n",
      "infrastructure_related       0.21      0.01      0.02       336\n",
      "             transport       0.56      0.07      0.12       228\n",
      "             buildings       0.67      0.13      0.22       252\n",
      "           electricity       0.80      0.04      0.08        95\n",
      "                 tools       0.00      0.00      0.00        30\n",
      "             hospitals       0.00      0.00      0.00        49\n",
      "                 shops       0.00      0.00      0.00        17\n",
      "           aid_centers       0.00      0.00      0.00        75\n",
      "  other_infrastructure       0.12      0.00      0.01       227\n",
      "       weather_related       0.83      0.60      0.70      1453\n",
      "                floods       0.87      0.36      0.51       417\n",
      "                 storm       0.75      0.44      0.55       465\n",
      "                  fire       1.00      0.04      0.07        52\n",
      "            earthquake       0.89      0.71      0.79       511\n",
      "                  cold       0.74      0.19      0.30       108\n",
      "         other_weather       0.44      0.05      0.09       249\n",
      "         direct_report       0.72      0.33      0.45      1012\n",
      "\n",
      "           avg / total       0.73      0.49      0.55     16399\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, X_test, Y_test, category_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filepath = 'classifier.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_filepath):\n",
    "    \"\"\"\n",
    "    Function to save trained model as pickle file.\n",
    "    :param model: Trained model (GridSearchCV Object)\n",
    "    :param model_filepath: Filepath to store model (string)\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    pickle.dump(model, open(model_filepath, 'wb'))\n",
    "    #pickle.dump(model,model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///DataBase.db')\n",
    "df = pd.read_sql('SELECT * FROM df', engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
